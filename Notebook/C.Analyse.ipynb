{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd2cd4c",
   "metadata": {},
   "source": [
    "# **Analysing Kaggle Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1092e0b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def overview(df):\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"\\nColumns and dtypes:\\n\", df.dtypes)\n",
    "    print(\"\\nNon-null counts:\\n\", df.count())\n",
    "    print(\"\\nMissing values per column:\\n\", df.isna().sum())\n",
    "    print(\"\\nBasic descriptive statistics for diet columns:\\n\")\n",
    "    display(df[diet_cols].describe().T)\n",
    "\n",
    "overview(country_dietary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa66be26",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_distributions(df):\n",
    "    for col in diet_cols:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        data = df[col].dropna()\n",
    "        plt.hist(data, bins=30)\n",
    "        plt.title(f\"Distribution: {col}\")\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"Count\")\n",
    "\n",
    "    # Scatter matrix of diet columns as per the intake\n",
    "    plt.figure(figsize=(12,12))\n",
    "\n",
    "plot_distributions(country_dietary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43abaf02",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def correlation_analysis(df):\n",
    "    corr = df[diet_cols].corr()\n",
    "    corr.to_csv(os.path.join(\"diet_columns_correlation.csv\"))\n",
    "    # Heatmap using matplotlib\n",
    "    plt.figure(figsize=(8,6))\n",
    "    im = plt.imshow(corr, vmin=-1, vmax=1)\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.xticks(range(len(diet_cols)), diet_cols, rotation=45, ha='right')\n",
    "    plt.yticks(range(len(diet_cols)), diet_cols)\n",
    "    plt.title(\"Correlation matrix (diet variables)\")\n",
    "    for (i, j), val in np.ndenumerate(corr.values):\n",
    "        plt.text(j, i, f\"{val:.2f}\", ha='center', va='center', fontsize=8, color='white' if abs(val)>0.5 else 'black')\n",
    "    return corr\n",
    "\n",
    "correlation_analysis(country_dietary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc8898",
   "metadata": {},
   "source": [
    "# **Analysing WHO Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23df614",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_single_dataset(df, dataset_name=\"Dataset\"):\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\" ANALYSIS FOR: {dataset_name}\")\n",
    "    print(f\"==============================\\n\")\n",
    "\n",
    "    # -----------------------\n",
    "    # 1. Year-wise trend\n",
    "    # -----------------------\n",
    "    try:\n",
    "        yearly = df.groupby(\"Year\")[\"Value_clean\"].mean().reset_index()\n",
    "        print(\"✔ YEARLY TREND (global mean):\")\n",
    "        print(yearly.head(), \"\\n\")\n",
    "    except:\n",
    "        print(\"⚠ Could not compute yearly trend\\n\")\n",
    "\n",
    "    # -----------------------\n",
    "    # 2. Country ranking\n",
    "    # -----------------------\n",
    "    try:\n",
    "        country_rank = (\n",
    "            df.groupby(\"Country\")[\"Value_clean\"]\n",
    "            .mean()\n",
    "            .sort_values(ascending=False)\n",
    "            .head(10)\n",
    "        )\n",
    "        print(\"✔ TOP 10 COUNTRIES:\")\n",
    "        print(country_rank, \"\\n\")\n",
    "    except:\n",
    "        print(\"⚠ Could not compute country ranking\\n\")\n",
    "\n",
    "    # -----------------------\n",
    "    # 3. Region-wise averages\n",
    "    # -----------------------\n",
    "    try:\n",
    "        region_avg = (\n",
    "            df.groupby(\"Region\")[\"Value_clean\"].mean().sort_values(ascending=False)\n",
    "        )\n",
    "        print(\"✔ REGION-WISE AVERAGE:\")\n",
    "        print(region_avg, \"\\n\")\n",
    "    except:\n",
    "        print(\"⚠ Could not compute region trends\\n\")\n",
    "\n",
    "    # -----------------------\n",
    "    # 4. Missing years per country\n",
    "    # -----------------------\n",
    "    try:\n",
    "        missing_years = (\n",
    "            df.groupby(\"Country\")[\"Year\"]\n",
    "            .apply(lambda x: sorted(set(range(min(x), max(x)+1)) - set(x)))\n",
    "        )\n",
    "        print(\"✔ MISSING YEARS PER COUNTRY:\")\n",
    "        print(missing_years.head(), \"\\n\")\n",
    "    except:\n",
    "        print(\"⚠ Could not compute missing years\\n\")\n",
    "\n",
    "    # -----------------------\n",
    "    # 5. Sex-wise trend (if exists)\n",
    "    # -----------------------\n",
    "    try:\n",
    "        sex_trend = df.groupby([\"Year\", \"Sex\"])[\"Value_clean\"].mean().reset_index()\n",
    "        print(\"✔ SEX-WISE TREND:\")\n",
    "        print(sex_trend.head(), \"\\n\")\n",
    "    except:\n",
    "        print(\"⚠ Sex data may be missing\\n\")\n",
    "\n",
    "    # -----------------------\n",
    "    # 6. Age-group trend (if exists)\n",
    "    # -----------------------\n",
    "    try:\n",
    "        age_trend = df.groupby([\"Year\", \"AgeGroup\"])[\"Value_clean\"].mean().reset_index()\n",
    "        print(\"✔ AGE-GROUP TREND:\")\n",
    "        print(age_trend.head(), \"\\n\")\n",
    "    except:\n",
    "        print(\"⚠ Age group data may be missing\\n\")\n",
    "\n",
    "    print(\"------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def analyze_all_datasets(datasets_dict):\n",
    "    for name, df in datasets_dict.items():\n",
    "        analyze_single_dataset(df, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c8b22c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "analyze_all_datasets(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2426085f",
   "metadata": {},
   "source": [
    "# **Analysis of merged Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18674423",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def rename_value(df, new_name):\n",
    "    df = df.copy()\n",
    "    df = df.rename(columns={\"Value_clean\": new_name})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dec98e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def minimize(df, colname):\n",
    "    df = df[[\"Country\", \"Year\", \"Value_clean\"]].copy()\n",
    "    df = df.rename(columns={\"Value_clean\": colname})\n",
    "    df = df.drop_duplicates(subset=[\"Country\", \"Year\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03520bf7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "adult_df = minimize(adult_obesity_age_standardized_cleaned, \"AdultObesity\")\n",
    "child_df = minimize(child_adolescent_obesity_crude_cleaned, \"ChildObesity\")\n",
    "over_u5_df = minimize(under5_overweight_prevalence_cleaned, \"Overweight_U5\")\n",
    "wasting_u5_df = minimize(under5_wasting_prevalence_cleaned, \"Wasting_U5\")\n",
    "stunting_u5_df = minimize(under5_stunting_prevalence_cleaned, \"Stunting_U5\")\n",
    "sugar_df = minimize(sugar_availability_per_capita_cleaned, \"Sugar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd4def",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(adult_df.shape, child_df.shape, over_u5_df.shape, wasting_u5_df.shape, stunting_u5_df.shape, sugar_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b1aa4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(min(adult_df['Year']), max(adult_df['Year']))\n",
    "print(min(child_df['Year']),max(child_df['Year']))\n",
    "print(min(over_u5_df['Year']), max(over_u5_df['Year']))\n",
    "print(min(wasting_u5_df['Year']), max(wasting_u5_df['Year']))\n",
    "print(min(stunting_u5_df['Year']), max(stunting_u5_df['Year']))\n",
    "print(min(sugar_df['Year']), max(sugar_df['Year']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71645bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(adult_df.shape, child_df.shape, over_u5_df.shape, wasting_u5_df.shape, stunting_u5_df.shape, sugar_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0383e7fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "adult_child_df = pd.merge(adult_df, child_df, on=['Country','Year'], how='inner')\n",
    "adult_child_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb6b65",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def compute_country_corr(df):\n",
    "    results = []\n",
    "\n",
    "    for country, sub in df.groupby(\"Country\"):\n",
    "        # Must have at least 2 years to compute correlation\n",
    "        if sub[[\"AdultObesity\", \"ChildObesity\"]].shape[0] >= 2:\n",
    "            corr = sub[\"AdultObesity\"].corr(sub[\"ChildObesity\"])\n",
    "        else:\n",
    "            corr = None\n",
    "\n",
    "        results.append([country, corr])\n",
    "\n",
    "    corr_df = pd.DataFrame(results, columns=[\"Country\", \"Correlation\"])\n",
    "    return corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1951ac7e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "corr_df = compute_country_corr(adult_child_df)\n",
    "\n",
    "corr_sample = corr_df.sample(20, random_state=42)   # pick 20 random countries\n",
    "corr_matrix = corr_sample.set_index(\"Country\")[[\"Correlation\"]]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Between Adult and Child Obesity (Sample of 20 Countries)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
